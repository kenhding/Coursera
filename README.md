# Coursera
My course work solutions and quiz answers


## Deep Learning Specialization

<details>
  <summary><b>Course 1 - Neural Networks and Deep Learning</b></summary>

#### Week 1 - Introduction to Deep Learning [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_1_Neural_Networks_and_Deep_Learning/Week1/DL_C1_week1_quiz_Introduction_to_deep_learning.png)

*Analyze the major trends driving the rise of deep learning, and give examples of where and how it is applied today.*


#### Week 2 - Neural Networks Basics [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_1_Neural_Networks_and_Deep_Learning/Week2/DL_C1_week2_quiz_Neural_Network_Basics.png)

*Set up a machine learning problem with a neural network mindset and use vectorization to speed up your models.*

[Python Basics With Numpy](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_1_Neural_Networks_and_Deep_Learning/Week2/DL_C1_week2_1_Python_Basics_With_Numpy_v3a.ipynb)

[Logistic Regression with a Neural Network mindset](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_1_Neural_Networks_and_Deep_Learning/Week2/DL_C1_week2_2_Logistic_Regression_with_a_Neural_Network_mindset_v6a.ipynb)


#### Week 3 - Shallow Neural Networks [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_1_Neural_Networks_and_Deep_Learning/Week3/DL_C1_week3_quiz_Shallow_Neural_Networks.png)

*Build a neural network with one hidden layer, using forward propagation and backpropagation.* 

[Planar data classification with one hidden layer](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_1_Neural_Networks_and_Deep_Learning/Week3/DL_C1_week3_Planar_data_classification_with_onehidden_layer_v6c.ipynb)


#### Week 4 - Deep Neural Networks [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_1_Neural_Networks_and_Deep_Learning/Week4/DL_C1_week4_quiz_Key_concepts_on_Deep_Neural_Networks.png)

*Analyze the key computations underlying deep learning, then use them to build and train deep neural networks for computer vision tasks.*

[Building your Deep Neural Network Step by Step](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_1_Neural_Networks_and_Deep_Learning/Week4/DL_C1_week4_1_Building_your_Deep_Neural_Network_Step_by_Step_v8a.ipynb)

[Deep Neural Network Application](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_1_Neural_Networks_and_Deep_Learning/Week4/DL_C1_week4_2_Deep%2BNeural%2BNetwork%2B-%2BApplication%2Bv8.ipynb)
</details>

<details>
  <summary><b>Course 2 - Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization</b></summary>

#### Week 1 - Practical Aspects of Deep Learning [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_2_Improving_Deep_Neural_Networks_Hyperparameter_Tuning_Regularization_and_Optimization/Week1/DL_C2_week1_quiz_Practical_aspects_of_Deep_Learning.png)

*Discover and experiment with a variety of different initialization methods, apply L2 regularization and dropout to avoid model overfitting, then apply gradient checking to identify errors in a fraud detection model.*

[Initialization](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_2_Improving_Deep_Neural_Networks_Hyperparameter_Tuning_Regularization_and_Optimization/Week1/DL_C2_week1_1_Initialization.ipynb)

[Regularization](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_2_Improving_Deep_Neural_Networks_Hyperparameter_Tuning_Regularization_and_Optimization/Week1/DL_C2_week1_2_Regularization.ipynb)

[Gradient Checking](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_2_Improving_Deep_Neural_Networks_Hyperparameter_Tuning_Regularization_and_Optimization/Week1/DL_C2_week1_3_Gradient_Checking.ipynb)


#### Week 2 - Optimization Algorithms [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_2_Improving_Deep_Neural_Networks_Hyperparameter_Tuning_Regularization_and_Optimization/Week2/DL_C2_week2_quiz_Optimization_Algorithms.png)

*Develop your deep learning toolbox by adding more advanced optimizations, random minibatching, and learning rate decay scheduling to speed up your models.*

[Optimization methods](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_2_Improving_Deep_Neural_Networks_Hyperparameter_Tuning_Regularization_and_Optimization/Week2/DL_C2_week2_Optimization_methods.ipynb)

#### Week 3 - Hyperparameter Tuning, Batch Normalization and Programming Frameworks [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_2_Improving_Deep_Neural_Networks_Hyperparameter_Tuning_Regularization_and_Optimization/Week3/DL_C2_week3_quiz_Hyperparameter_tuning_Batch_Normalization_Programming_Frameworks.png)

*Explore TensorFlow, a deep learning framework that allows you to build neural networks quickly and easily, then train a neural network on a TensorFlow dataset.*

[Tensorflow introduction](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_2_Improving_Deep_Neural_Networks_Hyperparameter_Tuning_Regularization_and_Optimization/Week3/DL_C2_week3_Tensorflow_introduction.ipynb)

</details>


<details>
  <summary><b>Course 3 - Structuring Machine Learning Projects </b></summary>
  
#### Week 1 - Bird Recognition in the City of Peacetopia (Case Study) [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_3_Structuring_Machine_Learning_Projects/Week1/DL_C3_week1_quiz_Bird_Recognition_in_the_City_of_Peacetopia_(Case_Study).png)
  
*Streamline and optimize your ML production workflow by implementing strategic guidelines for goal-setting and applying human-level performance to help define key priorities.*
  
#### Week 2 - Autonomous Driving (Case Study) [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_3_Structuring_Machine_Learning_Projects/Week2/DL_C3_week1_quiz_Autonomous_Driving_(Case_Study).png)
  
*Develop time-saving error analysis procedures to evaluate the most worthwhile options to pursue and gain intuition for how to split your data and when to use multi-task, transfer, and end-to-end deep learning.*

</details>


<details>
  <summary><b>Course 4 - Convolutional Neural Networks </b></summary>
  
  #### Week 1 - The Basics of ConvNets [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week1/DL_C4_week1_quiz_The_Basics_of_ConvNets.png)
  
  *Implement the foundational layers of CNNs (pooling, convolutions) and stack them properly in a deep network to solve multi-class image classification problems.*
  
  [Convolution model Step by Step](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week1/DL_C4_week1_1_Convolution_model_Step_by_Step.ipynb)
  
  
  [Convolution Model Application](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week1/DL_C4_week1_2_Convolution_Model_Application.ipynb)
  
  
  #### Week 2 - Deep Convolutional Models [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week2/DL_C4_week2_quiz_Deep_Convolutional_Models.png)
  
  *Discover some powerful practical tricks and methods used in deep CNNs, straight from the research papers, then apply transfer learning to your own deep CNN.*

  [Residual Networks](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week2/DL_C4_week2_1_Residual_Networks.ipynb)
  
  [Transfer learning with MobileNet v1](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week2/DL_C4_week2_2_Transfer_learning_with_MobileNet_v1.ipynb)
  

  #### Week 3 - Detection Algorithms [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week3/DL_C4_week3_quiz_Detection_Algorithms.png)
  
  *Apply your new knowledge of CNNs to one of the hottest (and most challenging!) fields in computer vision: object detection.*

  [Car detection with YOLO](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week2/DL_C4_week2_1_Residual_Networks.ipynb)
  
  [Image Segmentation with U-Net v2](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week3/DL_C4_week3_2_Image_Segmentation_with_U-Net_v2.ipynb)
  
  #### Week 4 - Face Recognition&Neural Style Transfer [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week4/DL_C4_week4_quiz_Face_Recognition%26Neural_Style_Transfer.png)
    
  *Explore how CNNs can be applied to multiple fields, including art generation and face recognition, then implement your own algorithm to generate art and recognize faces!*

  [Face Recognition](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week4/DL_C4_week4_1_Face_Recognition.ipynb)
  
  [Art Generation with Neural Style Transfer](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week4/DL_C4_week4_2_Art_Generation_with_Neural_Style_Transfer.ipynb)
  
  [Reference Papers](https://github.com/kenzo0619/Coursera/blob/master/Deep_Learning_Specialization/Course_4_Convolutional_Neural_Networks/Week4/DL_C4_week4_ref.png)

</details>

---

## Reinforcement Learning Specialization

<details>
  <summary><b>Course 1 - Fundamentals of Reinforcement Learning</b></summary>

#### Week 1 - An Introduction to Sequential Decision-Making [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_1_Fundamentals_of_Reinforcement_Learning/Week1/RL_C1_week1_quiz_Sequential_Decision_Making.png)

*For the first week of this course, you will learn how to understand the exploration-exploitation trade-off in sequential decision-making, implement incremental algorithms for estimating action-values, and compare the strengths and weaknesses to different algorithms for exploration. For this week’s graded assessment, you will implement and test an epsilon-greedy agent.*

[Bandits and Exploration and Exploitation](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_1_Fundamentals_of_Reinforcement_Learning/Week1/RL_C1_week1_Bandits_and_Exploration_and_Exploitation.ipynb)

#### Week 2 - Markov Decision Processes [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_1_Fundamentals_of_Reinforcement_Learning/Week2/RL_C1_week2_quiz_MDPs.png)

When you’re presented with a problem in industry, the first and most important step is to translate that problem into a Markov Decision Process (MDP). The quality of your solution depends heavily on how well you do this translation. This week, you will learn the definition of MDPs, you will understand goal-directed behavior and how this can be obtained from maximizing scalar rewards, and you will also understand the difference between episodic and continuing tasks. For this week’s graded assessment, you will create three example tasks of your own that fit into the MDP framework.

#### Week 3 - Value Functions & Bellman Equations [Quiz 1](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_1_Fundamentals_of_Reinforcement_Learning/Week3/RL_C1_week3_quiz_1_Value_Functions_and_Bellman_Equations.png) [Quiz 2](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_1_Fundamentals_of_Reinforcement_Learning/Week3/RL_C1_week3_quiz_2_Value_Functions_and_Bellman_Equations.png) 

Once the problem is formulated as an MDP, finding the optimal policy is more efficient when using value functions. This week, you will learn the definition of policies and value functions, as well as Bellman equations, which is the key technology that all of our algorithms will use.


#### Week 4 - Dynamic Programming [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_1_Fundamentals_of_Reinforcement_Learning/Week4/RL_C1_week4_quiz_Dynamic_Programming.png)

This week, you will learn how to compute value functions and optimal policies, assuming you have the MDP model. You will implement dynamic programming to compute value functions and optimal policies and understand the utility of dynamic programming for industrial applications and problems. Further, you will learn about Generalized Policy Iteration as a common template for constructing algorithms that maximize reward. For this week’s graded assessment, you will implement an efficient dynamic programming agent in a simulated industrial control problem.

[Optimal Policies with Dynamic Programming](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_1_Fundamentals_of_Reinforcement_Learning/Week4/RL_C1_week4_Optimal_Policies_with_Dynamic_Programming.ipynb)

</details>

<details>
  <summary><b>Course 2 - Sample-based Learning Methods</b></summary>

#### Week 1 - Monte Carlo Methods for Prediction & Control [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_2_Sample-based%20Learning%20Methods/Week1/RL_C2_week1_quiz_Monte_Carlo_Methods_for_Prediction_Control.png)

*This week you will learn how to estimate value functions and optimal policies, using only sampled experience from the environment. This module represents our first step toward incremental learning methods that learn from the agent’s own interaction with the world, rather than a model of the world. You will learn about on-policy and off-policy methods for prediction and control, using Monte Carlo methods---methods that use sampled returns. You will also be reintroduced to the exploration problem, but more generally in RL, beyond bandits.*

[Blackjack](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_2_Sample-based%20Learning%20Methods/Week1/RL_C2_week1_Blackjack.ipynb)

#### Week 2 - Temporal Difference Learning Methods for Prediction [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_2_Sample-based%20Learning%20Methods/Week2/RL_C2_week1_quiz_Temporal_Difference_Learning_Methods_for_Prediction.png)

*This week, you will learn about one of the most fundamental concepts in reinforcement learning: temporal difference (TD) learning. TD learning combines some of the features of both Monte Carlo and Dynamic Programming (DP) methods. TD methods are similar to Monte Carlo methods in that they can learn from the agent’s interaction with the world, and do not require knowledge of the model. TD methods are similar to DP methods in that they bootstrap, and thus can learn online---no waiting until the end of an episode. You will see how TD can learn more efficiently than Monte Carlo, due to bootstrapping. For this module, we first focus on TD for prediction, and discuss TD for control in the next module. This week, you will implement TD to estimate the value function for a fixed policy, in a simulated domain.*

[Policy Evaluation with Temporal Difference Learning](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_2_Sample-based%20Learning%20Methods/Week2/RL_C2_week1_Policy_Evaluation_with_Temporal_Difference_Learning.ipynb)

#### Week 3 - Temporal Difference Learning Methods for Control [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_2_Sample-based%20Learning%20Methods/Week3/RL_C2_week3_quiz_Temporal_Difference_Learning_Methods_for_Control.png)

*This week, you will learn about using temporal difference learning for control, as a generalized policy iteration strategy. You will see three different algorithms based on bootstrapping and Bellman equations for control: Sarsa, Q-learning and Expected Sarsa. You will see some of the differences between the methods for on-policy and off-policy control, and that Expected Sarsa is a unified algorithm for both. You will implement Expected Sarsa and Q-learning, on Cliff World.*

[Q-Learning and Expected Sarsa](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_2_Sample-based%20Learning%20Methods/Week3/RL_C2_week3_Q-Learning_and_Expected_Sarsa.ipynb)

#### Week 4 - Planning Learning Acting [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_2_Sample-based%20Learning%20Methods/Week4/RL_C2_week4_quiz_Planning_Learning_Acting.png)

*Up until now, you might think that learning with and without a model are two distinct, and in some ways, competing strategies: planning with Dynamic Programming verses sample-based learning via TD methods. This week we unify these two strategies with the Dyna architecture. You will learn how to estimate the model from data and then use this model to generate hypothetical experience (a bit like dreaming) to dramatically improve sample efficiency compared to sample-based methods like Q-learning. In addition, you will learn how to design learning systems that are robust to inaccurate models.*

[Dyna-Q and Dyna-Qplus](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_2_Sample-based%20Learning%20Methods/Week4/RL_C2_week4_Dyna-Q_and_Dyna-Qplus.ipynb)

  
</details>

<details>
  <summary><b>Course 3 - Prediction and Control with Function Approximation</b></summary>

#### Week 1 - On-policy Prediction with Approximation [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_3_Prediction_and_Control_with_Function_Approximation/Week1/RL_C3_week1_quiz_On-policy_Prediction_with_Approximation.png)
  
*This week you will learn how to estimate a value function for a given policy, when the number of states is much larger than the memory available to the agent. You will learn how to specify a parametric form of the value function, how to specify an objective function, and how estimating gradient descent can be used to estimate values from interaction with the world.*
  
[Semi-gradient TD(0) with State Aggregation](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_3_Prediction_and_Control_with_Function_Approximation/Week1/RL_C3_week1_Semi-gradient_TD(0)_with_State_Aggregation.ipynb)

#### Week 2 - Constructing Features for Prediction [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_3_Prediction_and_Control_with_Function_Approximation/Week2/RL_C3_week2_quiz_Constructing_Features_for_Prediction.png) 

*The features used to construct the agent’s value estimates are perhaps the most crucial part of a successful learning system. In this module we discuss two basic strategies for constructing features: (1) fixed basis that form an exhaustive partition of the input, and (2) adapting the features while the agent interacts with the world via Neural Networks and Backpropagation. In this week’s graded assessment you will solve a simple but infinite state prediction task with a Neural Network and TD learning.*
  
[Semi-gradient TD with a Neural Network](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_3_Prediction_and_Control_with_Function_Approximation/Week2/RL_C3_week2_Semi-gradient_TD_with_a_Neural_Network.ipynb)
  
#### Week 3 - Control with Approximation [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_3_Prediction_and_Control_with_Function_Approximation/Week3/RL_C3_week3_quiz_Control_with_Approximation.png)

*This week, you will see that the concepts and tools introduced in modules two and three allow straightforward extension of classic TD control methods to the function approximation setting. In particular, you will learn how to find the optimal policy in infinite-state MDPs by simply combining semi-gradient TD methods with generalized policy iteration, yielding classic control methods like Q-learning, and Sarsa. We conclude with a discussion of a new problem formulation for RL---average reward---which will undoubtedly be used in many applications of RL in the future.*
  
[Function Approximation and Control](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_3_Prediction_and_Control_with_Function_Approximation/Week3/RL_C3_week3_Function_Approximation_and_Control.ipynb)
  
#### Week 4 - Policy Gradient [Quiz](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_3_Prediction_and_Control_with_Function_Approximation/Week4/RL_C3_week4_quiz_Policy_Gradient_Methods.png)
  
*Every algorithm you have learned about so far estimates a value function as an intermediate step towards the goal of finding an optimal policy. An alternative strategy is to directly learn the parameters of the policy. This week you will learn about these policy gradient methods, and their advantages over value-function based methods. You will also learn how policy gradient methods can be used to find the optimal policy in tasks with both continuous state and action spaces.*
  
[Average Reward Softmax Actor-Critic using Tile-coding](https://github.com/kenzo0619/Coursera/blob/master/Reinforcement_Learning_Specialization/Course_3_Prediction_and_Control_with_Function_Approximation/Week4/RL_C3_week4_Average_Reward_Softmax_Actor-Critic_using_Tile-coding.ipynb)
  
</details>
  
---

## Practical Time Series Analysis
<details>
  <summary><b>Week 1-6</b></summary>
  
  
  
#### Week 1 - Basic Statistics [Quiz 1](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week1/PTSA_week1_quiz_Basic_Statistics_Review.png) [Quiz 2](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week1/PTSA_week1_quiz_Visualization.png)
  
*During this first week, we show how to download and install R on Windows and the Mac. We review those basics of inferential and descriptive statistics that you'll need during the course.*
  
[Measuring Linear Association with the Correlation Function](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week1/PTSA_week1_Measuring%20Linear%20Association%20with%20the%20Correlation%20Function.pdf)
  
#### Week 2 - Visualizing Time Series, and Beginning to Model Time Series [Quiz 1](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week2/PTSA_week2_quiz_Random_Walk_vs_Purely_Random_Process.png) [Quiz 2](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week2/PTSA_week2_quiz_Noise_Versus_Signal.png) [Quiz 3](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week2/PTSA_week2_quiz_Time_plots_Stationarity_ACV_ACF_Random_Walk_and_MA_processes.png)
  
*In this week, we begin to explore and visualize time series available as acquired data sets. We also take our first steps on developing the mathematical models needed to analyze time series data.*
  
[Introduction to Time Series](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week2/PTSA_week2_Introduction_to_Time_Series2.pdf)
  
#### Week 3 - Stationarity, MA(q) and AR(p) processes [Quiz 1](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_quiz_Stationarity.png) [Quiz 2](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_quiz_Series_Backward_Shift_Operator_Invertibility_and_Duality.png) [Quiz 3](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_quiz_Difference_equations_and_Yule-Walker_equations.png) [Quiz 4](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_quiz_AR(p)_and_the_ACF.png)
  
*In Week 3, we introduce few important notions in time series analysis: Stationarity, Backward shift operator, Invertibility, and Duality. We begin to explore Autoregressive processes and Yule-Walker equations.*
  
[Series and nseries representation](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_Series_and_series.pdf)
  
[Stationarity Intuition and Definition](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_Stationarity_Intuition_and_Definition.pdf)
  
[Stationarity White Noise Random Walks and Moving Averages](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_Stationarity_White_Noise_Random_Walks_and_Moving_Averages.pdf)

[Stationarity ACF of a Moving Average](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_Stationarity_ACF_of_a_Moving_Average.pdf)
  
[Autoregressive Processes Definition and First Examples](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_Autoregressive_Processes_Definition_and_First_Examples.pdf)

[Autoregressive Processes Backshift Operator and the ACF](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_Autoregressive_Processes_Backshift_Operator_and_the_ACF.pdf)
  
[Yule Walker equations](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week3/PTSA_week3_Yule_Walker_equations.pdf)
  

  
#### Week 4 - AR(p) processes, Yule-Walker equations, PACF [Quiz 1](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week4/PTSA_week4_quiz_Yule-Walker_in_matrix_form_and_Yule-Walker_estimation.png) [Quiz 2](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week4/PTSA_week4_quiz_Partial_Autocorrelation.png) [Quiz 3](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week4/PTSA_week4_quiz_LakeHuron_dataset.png)
  
*In this week, partial autocorrelation is introduced. We work more on Yule-Walker equations, and apply what we have learned so far to few real-world datasets.*
  
[Yule-Walker Equations in matrix form](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week4/PTSA_week4_Yule-Walker_Equations_in_matrix_form.pdf)
  
[Partial Autocorrelation and the PACF First Examples](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week4/PTSA_week4_Partial_Autocorrelation_and_the_PACF_First_Examples.pdf)
  
  
#### Week 5 - Akaike Information Criterion (AIC), Mixed Models, Integrated Models [Quiz 1](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week5/PTSA_week5_quiz_AIC_and_model_building.png) [Quiz 2](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week5/PTSA_week5_quiz_ARIMA_and_Q-statistic.png) [Quiz 3](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week5/PTSA_week5_quiz_ARMA_Processes.png) [Quiz 4](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week5/PTSA_week5_quiz_BJsales_dataset.png)
  
*In Week 5, we start working with Akaike Information criterion as a tool to judge our models, introduce mixed models such as ARMA, ARIMA and model few real-world datasets.*
  
[ARIMA processes](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week5/PTSA_week5_ARIMA_processes.pdf)
  
[Akaike Information Criterion and Model Quality](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week5/PTSA_week5_Akaike_Information_Criterion_and_Model_Quality.pdf)
  
[ARMA Properties and Examples](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week5/PTSA_week5_ARMA_Properties_and_Examples.pdf)
  
[ARMA Models and a Little Theory](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week5/PTSA_week5_ARMA_Models_and_a_Little_Theory.pdf)
  
#### Week 6 - Seasonality, SARIMA, Forecasting [Quiz 1](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week6/PTSA_week6_quiz_SARIMA_processes.png) [Quiz 2](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week6/PTSA_week6_quiz_USAccDeaths_dataset.png) [Quiz 3](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week6/PTSA_week6_quiz_Forecasting.png)
  
*In the last week of our course, another model is introduced: SARIMA. We fit SARIMA models to various datasets and start forecasting.*
  
[SARIMA processes](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week6/PTSA_week6_SARIMA_processes.pdf)
  
[Forecasting using Simple Exponential Smoothing](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week6/PTSA_week6_Forecasting_using_Simple_Exponential_Smoothing.pdf)
  
[Forecasting Using Holt Winters for Trend (Double Exponential)](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week6/PTSA_week6_Forecasting_Using_Holt_Winters_for_Trend_(Double_Exponential).pdf)
  
[Forecasting Using Holt Winters for Trend and Seasonality (Triple Exponential)](https://github.com/kenzo0619/Coursera/blob/master/Practical_Time_Series_Analysis/Week6/PTSA_week6_Forecasting%20Using%20Holt%20Winters%20for%20Trend%20and%20Seasonality%20(Triple%20Exponential).pdf)
  
</details>
  
  

  
  
